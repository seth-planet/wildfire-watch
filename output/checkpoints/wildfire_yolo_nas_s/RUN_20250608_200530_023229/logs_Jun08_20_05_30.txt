[2025-06-08 20:04:58] INFO - super_gradients.common.crash_handler.crash_tips_setup - Crash tips is enabled. You can set your environment variable to CRASH_HANDLER=FALSE to disable it
[2025-06-08 20:04:59] DEBUG - matplotlib - matplotlib data path: /usr/local/lib/python3.10/dist-packages/matplotlib/mpl-data
[2025-06-08 20:04:59] DEBUG - matplotlib - CONFIGDIR=/home/seth/.config/matplotlib
[2025-06-08 20:04:59] DEBUG - matplotlib - interactive is False
[2025-06-08 20:04:59] DEBUG - matplotlib - platform is linux
[2025-06-08 20:04:59] DEBUG - matplotlib - CACHEDIR=/home/seth/.cache/matplotlib
[2025-06-08 20:04:59] DEBUG - matplotlib.font_manager - Using fontManager instance from /home/seth/.cache/matplotlib/fontlist-v390.json
[2025-06-08 20:04:59] DEBUG - super_gradients.common.sg_loggers.clearml_sg_logger - Failed to import clearml
[2025-06-08 20:05:00] DEBUG - hydra.core.utils - Setting JobRuntime:name=UNKNOWN_NAME
[2025-06-08 20:05:00] DEBUG - hydra.core.utils - Setting JobRuntime:name=app
[2025-06-08 20:05:00] DEBUG - hydra.core.utils - Setting JobRuntime:name=app
[2025-06-08 20:05:00] INFO - __main__ - Starting YOLO-NAS training...
[2025-06-08 20:05:00] INFO - __main__ - Using device: None
[2025-06-08 20:05:00] INFO - __main__ - Creating YOLO-NAS dataloaders with real dataset...
[2025-06-08 20:05:00] INFO - __main__ - Creating training dataloader...
[2025-06-08 20:05:00] DEBUG - hydra.core.utils - Setting JobRuntime:name=app
[2025-06-08 20:05:01] INFO - super_gradients.training.datasets.detection_datasets.detection_dataset - Dataset Initialization in progress. `cache_annotations=True` causes the process to take longer due to full dataset indexing.
[2025-06-08 20:05:27] INFO - __main__ - Creating validation dataloader...
[2025-06-08 20:05:27] DEBUG - hydra.core.utils - Setting JobRuntime:name=app
[2025-06-08 20:05:27] INFO - super_gradients.training.datasets.detection_datasets.detection_dataset - Dataset Initialization in progress. `cache_annotations=True` causes the process to take longer due to full dataset indexing.
[2025-06-08 20:05:29] INFO - __main__ - âœ“ Real dataset dataloaders created successfully
[2025-06-08 20:05:29] INFO - __main__ - Training samples: 283618
[2025-06-08 20:05:29] INFO - __main__ - Validation samples: 21287
[2025-06-08 20:05:29] DEBUG - hydra.core.utils - Setting JobRuntime:name=app
[2025-06-08 20:05:29] INFO - __main__ - Model architecture: YoloNAS_S
[2025-06-08 20:05:29] INFO - __main__ - Number of classes: 32
[2025-06-08 20:05:29] INFO - __main__ - QAT (Quantization Aware Training) enabled
[2025-06-08 20:05:29] INFO - __main__ - QAT will start at epoch 150
[2025-06-08 20:05:29] WARNING - super_gradients.training.sg_trainer.sg_trainer - Train dataset size % batch_size != 0 and drop_last=False, this might result in smaller last batch.
[2025-06-08 20:05:30] INFO - super_gradients.training.sg_trainer.sg_trainer - Starting a new run with `run_id=RUN_20250608_200530_023229`
[2025-06-08 20:05:30] INFO - super_gradients.training.sg_trainer.sg_trainer - Checkpoints directory: ../output/checkpoints/wildfire_yolo_nas_s/RUN_20250608_200530_023229
[2025-06-08 20:05:30] INFO - super_gradients.training.sg_trainer.sg_trainer - Using EMA with params {'decay': 0.9999, 'decay_type': 'threshold'}
[2025-06-08 20:05:30] INFO - super_gradients.training.utils.sg_trainer_utils - TRAINING PARAMETERS:
    - Mode:                         OFF
    - Number of GPUs:               1          (1 available on the machine)
    - Full dataset size:            283618     (len(train_set))
    - Batch size per GPU:           8          (batch_size)
    - Batch Accumulate:             1          (batch_accumulate)
    - Total batch size:             8          (num_gpus * batch_size)
    - Effective Batch size:         8          (num_gpus * batch_size * batch_accumulate)
    - Iterations per epoch:         35453      (len(train_loader))
    - Gradient updates per epoch:   35453      (len(train_loader) / batch_accumulate)
    - Model: YoloNAS_S  (19.03M parameters, 19.03M optimized)
    - Learning Rates and Weight Decays:
      - default: (19.03M parameters). LR: 0.001 (19.03M parameters) WD: 0.0, (42.22K parameters), WD: 0.0001, (18.99M parameters)

[2025-06-08 20:05:30] INFO - super_gradients.training.sg_trainer.sg_trainer - Started training for 5 epochs (0/4)

