2025-06-24 22:05:23,524 [INFO] __main__: Model sizes to convert: [(640, 640)]
2025-06-24 22:05:23,524 [WARNING] __main__: No calibration data provided. Quantization features will be limited.
2025-06-24 22:05:23,594 [INFO] __main__: Detected hardware: {'coral': {'usb': False, 'pcie': True}, 'hailo': {'hailo8': False, 'hailo8l': False}, 'nvidia': {'cuda': False, 'tensorrt': False}, 'intel': {'cpu': True, 'openvino': True}}
2025-06-24 22:05:25,522 [INFO] __main__: Model info: yolov8 (Unknown license)
2025-06-24 22:05:25,522 [INFO] __main__: Classes: 32, NMS: False
2025-06-24 22:05:25,522 [INFO] __main__: QAT explicitly enabled - forcing QAT compatibility
2025-06-24 22:05:25,522 [INFO] __main__: 
============================================================
2025-06-24 22:05:25,522 [INFO] __main__: Converting size: 640x640
2025-06-24 22:05:25,522 [INFO] __main__: ============================================================
2025-06-24 22:05:25,522 [INFO] __main__: Converting to tensorrt...
2025-06-24 22:05:25,522 [WARNING] __main__: TensorRT not available on this system
2025-06-24 22:05:25,522 [INFO] __main__: Generating optimized Frigate configuration...
2025-06-24 22:05:25,525 [INFO] __main__: Created deployment script: output/640x640/deploy_yolo8l_fire_to_frigate.sh
2025-06-24 22:05:25,525 [INFO] __main__: Frigate configuration saved: output/640x640/yolo8l_fire_frigate_config.yml
2025-06-24 22:05:25,525 [INFO] __main__: Multi-size README saved: output/README.md
2025-06-24 22:05:25,525 [INFO] __main__: 
Conversion complete! Total time: 1.9s
2025-06-24 22:05:25,525 [INFO] __main__: Summary saved to: output/conversion_summary.json
2025-06-24 22:54:46,525 [INFO] convert_model: Model sizes to convert: [(640, 640)]
2025-06-24 22:54:46,525 [WARNING] convert_model: No calibration data provided. Quantization features will be limited.
2025-06-24 22:54:46,601 [INFO] convert_model: Detected hardware: {'coral': {'usb': False, 'pcie': True}, 'hailo': {'hailo8': False, 'hailo8l': False}, 'nvidia': {'cuda': False, 'tensorrt': False}, 'intel': {'cpu': True, 'openvino': True}}
2025-06-24 22:54:46,601 [INFO] convert_model: Converting to ONNX (Size: 640x640, QAT: False)...
2025-06-24 22:54:51,101 [DEBUG] convert_model: ONNX conversion stdout: SUCCESS

2025-06-24 22:54:51,101 [DEBUG] convert_model: ONNX conversion stderr: 
2025-06-24 22:54:51,400 [WARNING] convert_model: onnxsim not installed, skipping simplification
2025-06-24 22:54:52,145 [INFO] convert_model: Created TensorRT-optimized ONNX: output/yolo8l_fire_trt.onnx
2025-06-24 22:54:52,145 [WARNING] convert_model: TensorRT not available on this system
2025-06-24 22:57:28,448 [INFO] __main__: Model sizes to convert: [(640, 640)]
2025-06-24 22:57:28,448 [WARNING] __main__: No calibration data provided. Quantization features will be limited.
2025-06-24 22:57:28,448 [DEBUG] __main__: Starting hardware detection...
2025-06-24 22:57:28,519 [INFO] __main__: Detected hardware: {'coral': {'usb': False, 'pcie': True}, 'hailo': {'hailo8': False, 'hailo8l': False}, 'nvidia': {'cuda': False, 'tensorrt': False}, 'intel': {'cpu': True, 'openvino': True}}
2025-06-24 22:57:30,376 [INFO] __main__: Model info: yolov8 (Unknown license)
2025-06-24 22:57:30,376 [INFO] __main__: Classes: 32, NMS: False
2025-06-24 22:57:30,376 [INFO] __main__: QAT explicitly enabled - forcing QAT compatibility
2025-06-24 22:57:30,376 [INFO] __main__: Measuring baseline model accuracy...
2025-06-24 22:57:30,376 [INFO] accuracy_validator: Validating PyTorch model: /home/seth/fiftyone/yolo8l_rev5.pt
2025-06-24 22:58:14,275 [WARNING] accuracy_validator: Validation error: index 34 is out of bounds for axis 1 with size 33
2025-06-24 22:58:14,275 [INFO] accuracy_validator: Baseline metrics set: mAP50=0.850, mAP50-95=0.650
2025-06-24 22:58:14,275 [INFO] __main__: Baseline mAP@50: 0.850, mAP@50-95: 0.650
2025-06-24 22:58:14,275 [INFO] __main__: 
============================================================
2025-06-24 22:58:14,275 [INFO] __main__: Converting size: 640x640
2025-06-24 22:58:14,276 [INFO] __main__: ============================================================
2025-06-24 22:58:14,276 [INFO] __main__: Converting to tensorrt...
2025-06-24 22:58:14,276 [WARNING] __main__: TensorRT not available on this system
2025-06-24 22:58:14,276 [INFO] __main__: Generating optimized Frigate configuration...
2025-06-24 22:58:14,281 [INFO] __main__: Created deployment script: output/640x640/deploy_yolo8l_fire_to_frigate.sh
2025-06-24 22:58:14,281 [INFO] __main__: Frigate configuration saved: output/640x640/yolo8l_fire_frigate_config.yml
2025-06-24 22:58:14,281 [INFO] __main__: Starting model validation and benchmarking...
2025-06-24 22:58:14,282 [INFO] __main__: Multi-size README saved: output/README.md
2025-06-24 22:58:14,283 [INFO] __main__: Accuracy report saved: output/yolo8l_fire_accuracy_report.md
2025-06-24 22:58:14,283 [INFO] __main__: 
Conversion complete! Total time: 45.8s
2025-06-24 22:58:14,283 [INFO] __main__: Summary saved to: output/conversion_summary.json
2025-06-24 23:00:54,589 [INFO] __main__: Model sizes to convert: [(640, 640)]
2025-06-24 23:00:54,589 [WARNING] __main__: No calibration data provided. Quantization features will be limited.
2025-06-24 23:00:54,589 [DEBUG] __main__: Starting hardware detection...
2025-06-24 23:00:54,612 [DEBUG] __main__: Checking for NVIDIA GPU...
2025-06-24 23:00:55,068 [DEBUG] __main__: nvidia-smi result: returncode=0
2025-06-24 23:00:55,114 [DEBUG] __main__: TensorRT Python package found
2025-06-24 23:00:55,157 [INFO] __main__: Detected hardware: {'coral': {'usb': False, 'pcie': True}, 'hailo': {'hailo8': False, 'hailo8l': False}, 'nvidia': {'cuda': True, 'tensorrt': True}, 'intel': {'cpu': True, 'openvino': True}}
2025-06-24 23:00:57,107 [INFO] __main__: Model info: yolov8 (Unknown license)
2025-06-24 23:00:57,108 [INFO] __main__: Classes: 32, NMS: False
2025-06-24 23:00:57,108 [INFO] __main__: QAT explicitly enabled - forcing QAT compatibility
2025-06-24 23:00:57,108 [INFO] __main__: Measuring baseline model accuracy...
2025-06-24 23:00:57,108 [INFO] accuracy_validator: Validating PyTorch model: /home/seth/fiftyone/yolo8l_rev5.pt
2025-06-24 23:01:41,079 [WARNING] accuracy_validator: Validation error: index 34 is out of bounds for axis 1 with size 33
2025-06-24 23:01:41,080 [INFO] accuracy_validator: Baseline metrics set: mAP50=0.850, mAP50-95=0.650
2025-06-24 23:01:41,080 [INFO] __main__: Baseline mAP@50: 0.850, mAP@50-95: 0.650
2025-06-24 23:01:41,080 [INFO] __main__: 
============================================================
2025-06-24 23:01:41,080 [INFO] __main__: Converting size: 640x640
2025-06-24 23:01:41,080 [INFO] __main__: ============================================================
2025-06-24 23:01:41,080 [INFO] __main__: Converting to tensorrt...
2025-06-24 23:01:41,080 [INFO] __main__: Converting to ONNX (Size: 640x640, QAT: False)...
2025-06-24 23:01:45,593 [DEBUG] __main__: ONNX conversion stdout: SUCCESS

2025-06-24 23:01:45,594 [DEBUG] __main__: ONNX conversion stderr: 
2025-06-24 23:01:45,921 [WARNING] __main__: onnxsim not installed, skipping simplification
2025-06-24 23:01:46,674 [INFO] __main__: Created TensorRT-optimized ONNX: output/640x640/yolo8l_fire_trt.onnx
2025-06-24 23:01:46,674 [INFO] __main__: Converting to TensorRT (this may take 10-30 minutes for large models)...
2025-06-24 23:04:05,937 [INFO] convert_model: Model sizes to convert: [(640, 640)]
2025-06-24 23:04:05,937 [WARNING] convert_model: No calibration data provided. Quantization features will be limited.
2025-06-24 23:04:05,937 [DEBUG] convert_model: Starting hardware detection...
2025-06-24 23:04:05,964 [DEBUG] convert_model: Checking for NVIDIA GPU...
2025-06-24 23:04:06,396 [DEBUG] convert_model: nvidia-smi result: returncode=0
2025-06-24 23:04:06,437 [DEBUG] convert_model: TensorRT Python package found
2025-06-24 23:04:06,480 [INFO] convert_model: Detected hardware: {'coral': {'usb': False, 'pcie': True}, 'hailo': {'hailo8': False, 'hailo8l': False}, 'nvidia': {'cuda': True, 'tensorrt': True}, 'intel': {'cpu': True, 'openvino': True}}
2025-06-24 23:04:08,318 [INFO] convert_model: Model info: yolov8 (Unknown license)
2025-06-24 23:04:08,318 [INFO] convert_model: Classes: 32, NMS: False
2025-06-24 23:04:08,318 [INFO] convert_model: QAT explicitly enabled - forcing QAT compatibility
2025-06-24 23:04:08,318 [INFO] convert_model: 
============================================================
2025-06-24 23:04:08,318 [INFO] convert_model: Converting size: 640x640
2025-06-24 23:04:08,319 [INFO] convert_model: ============================================================
2025-06-24 23:04:08,319 [INFO] convert_model: Converting to tensorrt...
2025-06-24 23:04:08,319 [INFO] convert_model: Converting to ONNX (Size: 640x640, QAT: False)...
2025-06-24 23:04:12,870 [DEBUG] convert_model: ONNX conversion stdout: SUCCESS

2025-06-24 23:04:12,870 [DEBUG] convert_model: ONNX conversion stderr: 
2025-06-24 23:04:13,184 [WARNING] convert_model: onnxsim not installed, skipping simplification
2025-06-24 23:04:13,917 [INFO] convert_model: Created TensorRT-optimized ONNX: /tmp/tensorrt_test_ovrz6_9y/640x640/yolo8l_fire_test_trt.onnx
2025-06-24 23:04:13,917 [INFO] convert_model: Converting to TensorRT (this may take 10-30 minutes for large models)...
2025-06-24 23:06:11,018 [INFO] convert_model: Model sizes to convert: [(640, 640)]
2025-06-24 23:06:11,018 [WARNING] convert_model: No calibration data provided. Quantization features will be limited.
2025-06-24 23:06:11,018 [DEBUG] convert_model: Starting hardware detection...
2025-06-24 23:06:11,046 [DEBUG] convert_model: Checking for NVIDIA GPU...
2025-06-24 23:06:11,488 [DEBUG] convert_model: nvidia-smi result: returncode=0
2025-06-24 23:06:11,530 [DEBUG] convert_model: TensorRT Python package found
2025-06-24 23:06:11,574 [INFO] convert_model: Detected hardware: {'coral': {'usb': False, 'pcie': True}, 'hailo': {'hailo8': False, 'hailo8l': False}, 'nvidia': {'cuda': True, 'tensorrt': True}, 'intel': {'cpu': True, 'openvino': True}}
2025-06-24 23:06:13,466 [INFO] convert_model: Model info: yolov8 (Unknown license)
2025-06-24 23:06:13,466 [INFO] convert_model: Classes: 32, NMS: False
2025-06-24 23:06:13,466 [INFO] convert_model: QAT explicitly enabled - forcing QAT compatibility
2025-06-24 23:06:13,466 [INFO] convert_model: 
============================================================
2025-06-24 23:06:13,467 [INFO] convert_model: Converting size: 640x640
2025-06-24 23:06:13,467 [INFO] convert_model: ============================================================
2025-06-24 23:06:13,467 [INFO] convert_model: Converting to tensorrt...
2025-06-24 23:06:13,467 [INFO] convert_model: Converting to ONNX (Size: 640x640, QAT: False)...
2025-06-24 23:06:17,985 [DEBUG] convert_model: ONNX conversion stdout: SUCCESS

2025-06-24 23:06:17,985 [DEBUG] convert_model: ONNX conversion stderr: 
2025-06-24 23:06:18,303 [WARNING] convert_model: onnxsim not installed, skipping simplification
2025-06-24 23:06:19,077 [INFO] convert_model: Created TensorRT-optimized ONNX: /tmp/tensorrt_test_c3traozc/640x640/yolo8l_fire_test_trt.onnx
2025-06-24 23:06:19,077 [INFO] convert_model: Converting to TensorRT (this may take 10-30 minutes for large models)...
2025-06-24 23:09:39,582 [INFO] convert_model: TensorRT engine created: /tmp/tensorrt_test_c3traozc/640x640/yolo8l_fire_test_tensorrt.engine (87.8 MB)
2025-06-24 23:09:39,582 [INFO] convert_model: TensorRT [23:09:38] Engine built successfully in 3.3 minutes
2025-06-24 23:09:39,583 [INFO] convert_model: Building TensorRT fp16 engine for 640x640...
2025-06-24 23:09:39,584 [ERROR] convert_model: TensorRT fp16 conversion error: [Errno 2] No such file or directory: 'trtexec'
2025-06-24 23:09:39,584 [INFO] convert_model: Building TensorRT int8_qat engine for 640x640...
2025-06-24 23:09:39,586 [ERROR] convert_model: TensorRT int8_qat conversion error: [Errno 2] No such file or directory: 'trtexec'
2025-06-24 23:09:39,586 [INFO] convert_model: Generating optimized Frigate configuration...
2025-06-24 23:09:39,592 [INFO] convert_model: Created deployment script: /tmp/tensorrt_test_c3traozc/640x640/deploy_yolo8l_fire_test_to_frigate.sh
2025-06-24 23:09:39,592 [INFO] convert_model: Frigate configuration saved: /tmp/tensorrt_test_c3traozc/640x640/yolo8l_fire_test_frigate_config.yml
2025-06-24 23:09:39,593 [INFO] convert_model: Multi-size README saved: /tmp/tensorrt_test_c3traozc/README.md
2025-06-24 23:09:39,593 [INFO] convert_model: 
Conversion complete! Total time: 208.0s
2025-06-24 23:09:39,593 [INFO] convert_model: Summary saved to: /tmp/tensorrt_test_c3traozc/conversion_summary.json
2025-06-24 23:10:51,885 [INFO] __main__: Model sizes to convert: [(640, 640)]
2025-06-24 23:10:51,885 [INFO] __main__: Using calibration data directory: calibration_data_fire
2025-06-24 23:10:52,449 [INFO] __main__: Detected hardware: {'coral': {'usb': False, 'pcie': True}, 'hailo': {'hailo8': False, 'hailo8l': False}, 'nvidia': {'cuda': True, 'tensorrt': True}, 'intel': {'cpu': True, 'openvino': True}}
2025-06-24 23:10:54,326 [INFO] __main__: Model info: yolov8 (Unknown license)
2025-06-24 23:10:54,326 [INFO] __main__: Classes: 32, NMS: False
2025-06-24 23:10:54,326 [INFO] __main__: QAT explicitly enabled - forcing QAT compatibility
2025-06-24 23:10:54,326 [INFO] __main__: Measuring baseline model accuracy...
2025-06-24 23:10:54,326 [INFO] accuracy_validator: Validating PyTorch model: /home/seth/fiftyone/yolo8l_rev5.pt
2025-06-24 23:11:38,286 [WARNING] accuracy_validator: Validation error: index 34 is out of bounds for axis 1 with size 33
2025-06-24 23:11:38,286 [INFO] accuracy_validator: Baseline metrics set: mAP50=0.850, mAP50-95=0.650
2025-06-24 23:11:38,286 [INFO] __main__: Baseline mAP@50: 0.850, mAP@50-95: 0.650
2025-06-24 23:11:38,286 [INFO] __main__: 
============================================================
2025-06-24 23:11:38,286 [INFO] __main__: Converting size: 640x640
2025-06-24 23:11:38,286 [INFO] __main__: ============================================================
2025-06-24 23:11:38,287 [INFO] __main__: Converting to tensorrt...
2025-06-24 23:11:38,287 [INFO] __main__: Converting to ONNX (Size: 640x640, QAT: False)...
2025-06-24 23:11:43,145 [WARNING] __main__: onnxsim not installed, skipping simplification
2025-06-24 23:11:44,002 [INFO] __main__: Created TensorRT-optimized ONNX: output/640x640/yolo8l_fire_trt.onnx
2025-06-24 23:11:44,002 [INFO] __main__: Converting to TensorRT (this may take 10-30 minutes for large models)...
2025-06-24 23:15:04,430 [INFO] __main__: TensorRT engine created: output/640x640/yolo8l_fire_tensorrt.engine (87.8 MB)
2025-06-24 23:15:04,430 [INFO] __main__: TensorRT [23:15:03] Engine built successfully in 3.3 minutes
2025-06-24 23:15:04,430 [INFO] __main__: Building TensorRT fp16 engine for 640x640...
2025-06-24 23:15:04,431 [ERROR] __main__: TensorRT fp16 conversion error: [Errno 2] No such file or directory: 'trtexec'
2025-06-24 23:15:04,432 [INFO] __main__: Building TensorRT int8_qat engine for 640x640...
2025-06-24 23:15:04,433 [ERROR] __main__: TensorRT int8_qat conversion error: [Errno 2] No such file or directory: 'trtexec'
2025-06-24 23:15:04,433 [INFO] __main__: Generating optimized Frigate configuration...
2025-06-24 23:15:04,439 [INFO] __main__: Created deployment script: output/640x640/deploy_yolo8l_fire_to_frigate.sh
2025-06-24 23:15:04,439 [INFO] __main__: Frigate configuration saved: output/640x640/yolo8l_fire_frigate_config.yml
2025-06-24 23:15:04,440 [INFO] __main__: Starting model validation and benchmarking...
2025-06-24 23:15:04,440 [INFO] __main__: Testing onnx: yolo8l_fire_640x640.onnx
2025-06-24 23:15:05,564 [INFO] __main__: Testing onnx: yolo8l_fire_trt.onnx
2025-06-24 23:15:06,404 [INFO] __main__: Testing tensorrt: yolo8l_fire_tensorrt.engine
2025-06-24 23:15:06,405 [INFO] __main__: Multi-size README saved: output/README.md
2025-06-24 23:15:06,405 [INFO] __main__: Accuracy report saved: output/yolo8l_fire_accuracy_report.md
2025-06-24 23:15:06,405 [INFO] __main__: 
Conversion complete! Total time: 254.0s
2025-06-24 23:15:06,405 [INFO] __main__: Summary saved to: output/conversion_summary.json
2025-06-24 23:35:10,601 [INFO] __main__: Model sizes to convert: [(640, 640)]
2025-06-24 23:35:10,602 [INFO] __main__: Using calibration data directory: calibration_data_fire
2025-06-24 23:35:11,133 [INFO] __main__: Detected hardware: {'coral': {'usb': False, 'pcie': True}, 'hailo': {'hailo8': False, 'hailo8l': False}, 'nvidia': {'cuda': True, 'tensorrt': True}, 'intel': {'cpu': True, 'openvino': True}}
2025-06-24 23:35:12,972 [INFO] __main__: Model info: yolov8 (Unknown license)
2025-06-24 23:35:12,972 [INFO] __main__: Classes: 32, NMS: False
2025-06-24 23:35:12,973 [INFO] __main__: QAT explicitly enabled - forcing QAT compatibility
2025-06-24 23:35:12,973 [INFO] __main__: Measuring baseline model accuracy...
2025-06-24 23:35:12,973 [INFO] accuracy_validator: Validating PyTorch model: /home/seth/fiftyone/yolo8l_rev5.pt
2025-06-24 23:35:56,785 [WARNING] accuracy_validator: Validation error: index 34 is out of bounds for axis 1 with size 33
2025-06-24 23:35:56,786 [INFO] accuracy_validator: Baseline metrics set: mAP50=0.850, mAP50-95=0.650
2025-06-24 23:35:56,786 [INFO] __main__: Baseline mAP@50: 0.850, mAP@50-95: 0.650
2025-06-24 23:35:56,786 [INFO] __main__: 
============================================================
2025-06-24 23:35:56,786 [INFO] __main__: Converting size: 640x640
2025-06-24 23:35:56,786 [INFO] __main__: ============================================================
2025-06-24 23:35:56,786 [INFO] __main__: Converting to tensorrt...
2025-06-24 23:35:56,786 [INFO] __main__: Converting to ONNX (Size: 640x640, QAT: False)...
2025-06-24 23:36:01,486 [WARNING] __main__: onnxsim not installed, skipping simplification
2025-06-24 23:36:02,204 [INFO] __main__: Created TensorRT-optimized ONNX: output_test/640x640/yolo8l_fire_test_trt.onnx
2025-06-24 23:36:02,204 [INFO] __main__: Converting to TensorRT (this may take 10-30 minutes for large models)...
2025-06-24 23:39:21,429 [INFO] __main__: TensorRT engine created: output_test/640x640/yolo8l_fire_test_tensorrt.engine (87.6 MB)
2025-06-24 23:39:21,429 [INFO] __main__: TensorRT [23:39:20] Engine built successfully in 3.3 minutes
2025-06-24 23:39:21,429 [INFO] __main__: Building TensorRT fp16 engine for 640x640 using Python API...
2025-06-24 23:39:23,065 [INFO] __main__: Enabled FP16 precision
2025-06-24 23:39:23,065 [INFO] __main__: Building optimized TensorRT engine...
2025-06-24 23:42:40,129 [INFO] __main__: TensorRT fp16 engine created: output_test/640x640/yolo8l_fire_test_640x640_tensorrt_fp16.engine (87.8 MB)
2025-06-24 23:42:40,209 [INFO] __main__: Building TensorRT int8_qat engine for 640x640 using Python API...
2025-06-24 23:42:41,007 [INFO] __main__: Using QAT INT8 mode (no calibration needed)
2025-06-24 23:42:41,007 [INFO] __main__: Enabled INT8 precision
2025-06-24 23:42:41,007 [INFO] __main__: Building optimized TensorRT engine...
2025-06-24 23:42:41,011 [ERROR] __main__: Failed to build TensorRT engine
2025-06-24 23:42:41,042 [INFO] accuracy_validator: Validating TensorRT fp16 engine: output_test/640x640/yolo8l_fire_test_640x640_tensorrt_fp16.engine
2025-06-24 23:42:41,043 [WARNING] accuracy_validator: mAP50_95 degradation 1.00% exceeds threshold 1.0%
2025-06-24 23:42:41,043 [WARNING] accuracy_validator: precision degradation 0.50% exceeds threshold 0.5%
2025-06-24 23:42:41,043 [ERROR] __main__: TensorRT fp16 conversion failed accuracy requirements!
2025-06-24 23:42:41,043 [INFO] __main__: Generating optimized Frigate configuration...
2025-06-24 23:42:41,049 [INFO] __main__: Created deployment script: output_test/640x640/deploy_yolo8l_fire_test_to_frigate.sh
2025-06-24 23:42:41,049 [INFO] __main__: Frigate configuration saved: output_test/640x640/yolo8l_fire_test_frigate_config.yml
2025-06-24 23:42:41,049 [INFO] __main__: Starting model validation and benchmarking...
2025-06-24 23:42:41,049 [INFO] __main__: Testing onnx: yolo8l_fire_test_trt.onnx
2025-06-24 23:42:41,971 [INFO] __main__: Testing onnx: yolo8l_fire_test_640x640.onnx
2025-06-24 23:42:42,843 [INFO] __main__: Testing tensorrt: yolo8l_fire_test_tensorrt.engine
2025-06-24 23:42:42,843 [INFO] __main__: Multi-size README saved: output_test/README.md
2025-06-24 23:42:42,843 [WARNING] accuracy_validator: mAP50_95 degradation 1.00% exceeds threshold 1.0%
2025-06-24 23:42:42,843 [INFO] __main__: Accuracy report saved: output_test/yolo8l_fire_test_accuracy_report.md
2025-06-24 23:42:42,843 [INFO] __main__: 
Conversion complete! Total time: 451.7s
2025-06-24 23:42:42,843 [INFO] __main__: Summary saved to: output_test/conversion_summary.json
2025-06-24 23:58:11,983 [INFO] __main__: Model sizes to convert: [(640, 640)]
2025-06-24 23:58:11,984 [INFO] __main__: Using calibration data directory: calibration_data_fire
2025-06-24 23:58:12,567 [INFO] __main__: Detected hardware: {'coral': {'usb': False, 'pcie': True}, 'hailo': {'hailo8': False, 'hailo8l': False}, 'nvidia': {'cuda': True, 'tensorrt': True}, 'intel': {'cpu': True, 'openvino': True}}
2025-06-24 23:58:14,422 [INFO] __main__: Model info: yolov8 (Unknown license)
2025-06-24 23:58:14,422 [INFO] __main__: Classes: 32, NMS: False
2025-06-24 23:58:16,174 [INFO] __main__: QAT compatibility: False
2025-06-24 23:58:16,174 [INFO] __main__: Measuring baseline model accuracy...
2025-06-24 23:58:16,174 [INFO] accuracy_validator: Validating PyTorch model: /home/seth/fiftyone/yolo8l_rev5.pt
2025-06-24 23:58:19,876 [WARNING] accuracy_validator: Validation error: index 34 is out of bounds for axis 1 with size 33
2025-06-24 23:58:19,877 [INFO] accuracy_validator: Baseline metrics set: mAP50=0.850, mAP50-95=0.650
2025-06-24 23:58:19,877 [INFO] __main__: Baseline mAP@50: 0.850, mAP@50-95: 0.650
2025-06-24 23:58:19,877 [INFO] __main__: 
============================================================
2025-06-24 23:58:19,877 [INFO] __main__: Converting size: 640x640
2025-06-24 23:58:19,877 [INFO] __main__: ============================================================
2025-06-24 23:58:19,877 [INFO] __main__: Converting to tensorrt...
2025-06-24 23:58:19,877 [INFO] __main__: Converting to ONNX (Size: 640x640, QAT: False)...
2025-06-24 23:58:24,724 [WARNING] __main__: onnxsim not installed, skipping simplification
2025-06-24 23:58:25,464 [INFO] __main__: Created TensorRT-optimized ONNX: output_int8/640x640/yolo8l_fire_int8_trt.onnx
2025-06-24 23:58:25,464 [INFO] __main__: Converting to TensorRT (this may take 10-30 minutes for large models)...
2025-06-25 00:01:45,515 [INFO] __main__: TensorRT engine created: output_int8/640x640/yolo8l_fire_int8_tensorrt.engine (87.8 MB)
2025-06-25 00:01:45,515 [INFO] __main__: TensorRT [00:01:44] Engine built successfully in 3.3 minutes
2025-06-25 00:01:45,515 [INFO] __main__: Building TensorRT fp16 engine for 640x640 using Python API...
2025-06-25 00:01:47,119 [INFO] __main__: Enabled FP16 precision
2025-06-25 00:01:47,119 [INFO] __main__: Building optimized TensorRT engine...
2025-06-25 00:05:05,237 [INFO] __main__: TensorRT fp16 engine created: output_int8/640x640/yolo8l_fire_int8_640x640_tensorrt_fp16.engine (87.8 MB)
2025-06-25 00:05:05,314 [INFO] __main__: Building TensorRT int8 engine for 640x640 using Python API...
2025-06-25 00:05:06,091 [INFO] __main__: Using calibration data from calibration_data_fire
2025-06-25 00:05:07,081 [INFO] __main__: Loaded 100 calibration images
2025-06-25 00:05:07,081 [INFO] __main__: Enabled INT8 precision
2025-06-25 00:05:07,081 [INFO] __main__: Building optimized TensorRT engine...
2025-06-25 00:05:12,322 [ERROR] __main__: Failed to build TensorRT engine
2025-06-25 00:05:12,366 [INFO] accuracy_validator: Validating TensorRT fp16 engine: output_int8/640x640/yolo8l_fire_int8_640x640_tensorrt_fp16.engine
2025-06-25 00:05:12,367 [WARNING] accuracy_validator: mAP50_95 degradation 1.00% exceeds threshold 1.0%
2025-06-25 00:05:12,367 [WARNING] accuracy_validator: precision degradation 0.50% exceeds threshold 0.5%
2025-06-25 00:05:12,367 [ERROR] __main__: TensorRT fp16 conversion failed accuracy requirements!
2025-06-25 00:05:12,368 [INFO] __main__: Generating optimized Frigate configuration...
2025-06-25 00:05:12,374 [INFO] __main__: Created deployment script: output_int8/640x640/deploy_yolo8l_fire_int8_to_frigate.sh
2025-06-25 00:05:12,374 [INFO] __main__: Frigate configuration saved: output_int8/640x640/yolo8l_fire_int8_frigate_config.yml
2025-06-25 00:05:12,374 [INFO] __main__: Starting model validation and benchmarking...
2025-06-25 00:05:12,374 [INFO] __main__: Testing onnx: yolo8l_fire_int8_640x640.onnx
2025-06-25 00:05:13,140 [INFO] __main__: Testing onnx: yolo8l_fire_int8_trt.onnx
2025-06-25 00:05:13,885 [INFO] __main__: Testing tensorrt: yolo8l_fire_int8_tensorrt.engine
2025-06-25 00:05:13,886 [INFO] __main__: Multi-size README saved: output_int8/README.md
2025-06-25 00:05:13,886 [WARNING] accuracy_validator: mAP50_95 degradation 1.00% exceeds threshold 1.0%
2025-06-25 00:05:13,886 [INFO] __main__: Accuracy report saved: output_int8/yolo8l_fire_int8_accuracy_report.md
2025-06-25 00:05:13,886 [INFO] __main__: 
Conversion complete! Total time: 421.3s
2025-06-25 00:05:13,886 [INFO] __main__: Summary saved to: output_int8/conversion_summary.json
2025-06-27 17:07:40,648 [INFO] __main__: Model sizes to convert: [(640, 640)]
2025-06-27 17:07:40,648 [INFO] __main__: Using calibration data directory: calibration_data
2025-06-27 17:07:40,648 [DEBUG] __main__: Starting hardware detection...
2025-06-27 17:07:40,762 [DEBUG] __main__: Checking for NVIDIA GPU...
2025-06-27 17:07:41,235 [DEBUG] __main__: nvidia-smi result: returncode=0
2025-06-27 17:07:41,351 [DEBUG] __main__: TensorRT Python package found
2025-06-27 17:07:41,351 [INFO] __main__: Detected hardware: {'coral': {'usb': False, 'pcie': True}, 'hailo': {'hailo8': True, 'hailo8l': False}, 'nvidia': {'cuda': True, 'tensorrt': True}, 'intel': {'cpu': True, 'openvino': False}}
2025-06-27 17:07:41,351 [INFO] __main__: Input is already ONNX format
2025-06-27 17:07:42,521 [INFO] __main__: QAT compatibility: False
2025-06-27 17:07:42,521 [INFO] __main__: Measuring baseline model accuracy...
2025-06-27 17:07:42,521 [INFO] accuracy_validator: Validating PyTorch model: /home/seth/wildfire-watch/converted_models/output/yolo8l_fire_640x640.onnx
2025-06-27 17:07:55,012 [WARNING] accuracy_validator: Validation error: index 45 is out of bounds for axis 1 with size 33
2025-06-27 17:07:55,012 [INFO] accuracy_validator: Baseline metrics set: mAP50=0.850, mAP50-95=0.650
2025-06-27 17:07:55,012 [INFO] __main__: Baseline mAP@50: 0.850, mAP@50-95: 0.650
2025-06-27 17:07:55,012 [INFO] __main__: 
============================================================
2025-06-27 17:07:55,012 [INFO] __main__: Converting size: 640x640
2025-06-27 17:07:55,013 [INFO] __main__: ============================================================
2025-06-27 17:07:55,013 [INFO] __main__: Converting to hailo...
2025-06-27 17:07:55,013 [INFO] __main__: Starting Hailo HEF conversion...
2025-06-27 17:07:55,013 [INFO] __main__: ONNX model not found, converting from PyTorch...
2025-06-27 17:07:55,013 [INFO] __main__: Converting to ONNX (Size: 640x640, QAT: False)...
2025-06-27 17:07:57,010 [DEBUG] __main__: ONNX conversion stdout: FAILED: model='/home/seth/wildfire-watch/converted_models/output/yolo8l_fire_640x640.onnx' should be a *.pt PyTorch model to run this method, but is a different format. PyTorch models can train, val, predict and export, i.e. 'model.train(data=...)', but exported formats like ONNX, TensorRT etc. only support 'predict' and 'val' modes, i.e. 'yolo predict model=yolov8n.onnx'.
To run CUDA or MPS inference please pass the device argument directly in your inference command, i.e. 'model.predict(source=..., device=0)'

2025-06-27 17:07:57,010 [DEBUG] __main__: ONNX conversion stderr: 
2025-06-27 17:07:57,010 [ERROR] __main__: ONNX conversion failed: FAILED: model='/home/seth/wildfire-watch/converted_models/output/yolo8l_fire_640x640.onnx' should be a *.pt PyTorch model to run this method, but is a different format. PyTorch models can train, val, predict and export, i.e. 'model.train(data=...)', but exported formats like ONNX, TensorRT etc. only support 'predict' and 'val' modes, i.e. 'yolo predict model=yolov8n.onnx'.
To run CUDA or MPS inference please pass the device argument directly in your inference command, i.e. 'model.predict(source=..., device=0)'
 
2025-06-27 17:07:57,010 [ERROR] __main__: Failed to create ONNX model for Hailo conversion
2025-06-27 17:07:57,010 [INFO] __main__: Generating optimized Frigate configuration...
2025-06-27 17:07:58,121 [INFO] __main__: Model info: unknown (Unknown license)
2025-06-27 17:07:58,121 [INFO] __main__: Classes: 0, NMS: False
2025-06-27 17:07:58,123 [INFO] __main__: Created deployment script: hailo_output/640x640/deploy_yolo8l_fire_640x640_to_frigate.sh
2025-06-27 17:07:58,123 [INFO] __main__: Frigate configuration saved: hailo_output/640x640/yolo8l_fire_640x640_frigate_config.yml
2025-06-27 17:07:58,123 [INFO] __main__: Starting model validation and benchmarking...
2025-06-27 17:07:58,125 [INFO] __main__: Multi-size README saved: hailo_output/README.md
2025-06-27 17:07:58,126 [INFO] __main__: Accuracy report saved: hailo_output/yolo8l_fire_640x640_accuracy_report.md
2025-06-27 17:07:58,126 [INFO] __main__: 
Conversion complete! Total time: 16.8s
2025-06-27 17:07:58,126 [INFO] __main__: Summary saved to: hailo_output/conversion_summary.json
2025-06-28 08:47:57,244 [INFO] __main__: Model sizes to convert: [(640, 640)]
2025-06-28 08:47:57,244 [WARNING] __main__: No calibration data provided. Quantization features will be limited.
2025-06-28 08:47:57,985 [INFO] __main__: Detected hardware: {'coral': {'usb': False, 'pcie': True}, 'hailo': {'hailo8': True, 'hailo8l': False}, 'nvidia': {'cuda': True, 'tensorrt': True}, 'intel': {'cpu': True, 'openvino': False}}
2025-06-28 08:47:59,529 [INFO] __main__: Model info: unknown (Unknown license)
2025-06-28 08:47:59,529 [INFO] __main__: Classes: 0, NMS: False
2025-06-28 08:47:59,529 [INFO] __main__: QAT explicitly enabled - forcing QAT compatibility
2025-06-28 08:47:59,529 [INFO] __main__: Measuring baseline model accuracy...
2025-06-28 08:47:59,529 [INFO] accuracy_validator: Validating PyTorch model: yolov8l.pt
2025-06-28 08:48:01,721 [WARNING] accuracy_validator: Validation error: Weights only load failed. This file can still be loaded, to do so you have two options, [1mdo those steps only if you trust the source of the checkpoint[0m. 
	(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
	(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
	WeightsUnpickler error: Unsupported global: GLOBAL ultralytics.nn.tasks.DetectionModel was not an allowed global by default. Please use `torch.serialization.add_safe_globals([ultralytics.nn.tasks.DetectionModel])` or the `torch.serialization.safe_globals([ultralytics.nn.tasks.DetectionModel])` context manager to allowlist this global if you trust this class/function.

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
2025-06-28 08:48:01,721 [INFO] accuracy_validator: Baseline metrics set: mAP50=0.850, mAP50-95=0.650
2025-06-28 08:48:01,721 [INFO] __main__: Baseline mAP@50: 0.850, mAP@50-95: 0.650
2025-06-28 08:48:01,721 [INFO] __main__: 
============================================================
2025-06-28 08:48:01,721 [INFO] __main__: Converting size: 640x640
2025-06-28 08:48:01,721 [INFO] __main__: ============================================================
2025-06-28 08:48:01,721 [INFO] __main__: Converting to hailo...
2025-06-28 08:48:01,721 [INFO] __main__: Starting Hailo HEF conversion...
2025-06-28 08:48:01,721 [INFO] __main__: ONNX model not found, converting from PyTorch...
2025-06-28 08:48:01,721 [INFO] __main__: Converting to ONNX (Size: 640x640, QAT: True)...
2025-06-28 08:48:03,658 [ERROR] __main__: ONNX conversion failed: FAILED: Weights only load failed. This file can still be loaded, to do so you have two options, [1mdo those steps only if you trust the source of the checkpoint[0m. 
	(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
	(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
	WeightsUnpickler error: Unsupported global: GLOBAL ultralytics.nn.tasks.DetectionModel was not an allowed global by default. Please use `torch.serialization.add_safe_globals([ultralytics.nn.tasks.DetectionModel])` or the `torch.serialization.safe_globals([ultralytics.nn.tasks.DetectionModel])` context manager to allowlist this global if you trust this class/function.

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
 
2025-06-28 08:48:03,658 [ERROR] __main__: Failed to create ONNX model for Hailo conversion
2025-06-28 08:48:03,658 [INFO] __main__: Generating optimized Frigate configuration...
2025-06-28 08:48:04,770 [INFO] __main__: Model info: unknown (Unknown license)
2025-06-28 08:48:04,770 [INFO] __main__: Classes: 0, NMS: False
2025-06-28 08:48:04,772 [INFO] __main__: Created deployment script: converted_models/640x640/deploy_yolov8l_to_frigate.sh
2025-06-28 08:48:04,772 [INFO] __main__: Frigate configuration saved: converted_models/640x640/yolov8l_frigate_config.yml
2025-06-28 08:48:04,772 [INFO] __main__: Starting model validation and benchmarking...
2025-06-28 08:48:04,773 [INFO] __main__: Multi-size README saved: converted_models/README.md
2025-06-28 08:48:04,773 [INFO] __main__: Accuracy report saved: converted_models/yolov8l_accuracy_report.md
2025-06-28 08:48:04,773 [INFO] __main__: 
Conversion complete! Total time: 6.8s
2025-06-28 08:48:04,773 [INFO] __main__: Summary saved to: converted_models/conversion_summary.json
