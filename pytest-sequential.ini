[pytest]
# Configuration for running integration tests sequentially to avoid conflicts

testpaths = tests

# Exclude directories
norecursedirs = .* build dist CVS _darcs {arch} *.egg tmp output scripts __pycache__ venv .venv demo_output certs docs mosquitto_data converted_models

# Test file patterns
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Run sequentially (no xdist)
addopts = 
    -v
    --tb=short
    --strict-markers
    --color=yes
    --durations=10
    --maxfail=10
    --ignore=tmp/
    --ignore=output/
    --ignore=scripts/
    --ignore=demo_output/
    --ignore=certs/
    --ignore=docs/
    --ignore=mosquitto_data/
    --ignore=converted_models/
    -m "integration or e2e or docker"

# Timeout settings 
timeout = 3600
timeout_method = thread
timeout_func_only = true

# All markers (copy from main pytest.ini)
markers =
    slow: marks tests as slow (may take >30 seconds)
    integration: marks tests as integration tests (require external services)
    hardware: marks tests requiring hardware (Raspberry Pi, Coral TPU, etc.)
    network: marks tests requiring network access
    mqtt: marks tests requiring MQTT broker
    docker: marks tests requiring Docker
    coral: marks tests requiring Coral TPU hardware
    coral_tpu: marks tests requiring Coral TPU hardware (alias)
    gpu: marks tests requiring GPU hardware
    hailo: marks tests requiring Hailo AI accelerator
    api_usage: marks tests for API usage validation
    yolo_nas: marks tests for YOLO-NAS training/inference
    super_gradients: marks tests requiring super-gradients library
    qat: marks tests for quantization-aware training
    qat_functionality: marks tests for quantization-aware training (alias)
    int8: marks tests for INT8 model quantization
    int8_quantization: marks tests for INT8 model quantization (alias)
    frigate_integration: marks tests for Frigate NVR integration
    model_converter: marks tests for model format conversion
    model_conversion: marks tests for model format conversion (alias)
    hardware_integration: marks tests for hardware integration
    deployment: marks tests for production deployment
    security_nvr: marks tests for security NVR functionality
    timeout_expected: marks tests that are expected to have long timeouts
    infrastructure_dependent: marks tests that depend on slow infrastructure
    e2e: marks tests as end-to-end tests
    python38: marks tests requiring Python 3.8
    python310: marks tests requiring Python 3.10
    python312: marks tests requiring Python 3.12
    tflite_runtime: marks tests requiring TensorFlow Lite runtime
    benchmark: marks performance benchmark tests
    cameras: marks tests involving camera functionality
    stress: marks stress/load tests

# Logging
log_level = INFO
log_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s

# Disable warnings if needed
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning